{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "joint-military",
   "metadata": {},
   "source": [
    "# Developing the Text Generation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-credit",
   "metadata": {},
   "source": [
    "First of all, the text generation that I will be using requires a prompt. For that I'll take the first 10 words of the 27k+ rows of data I have, and use those for the prompts. I'm okay with 10 characters being \"predetermined\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ideal-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affiliated-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_TOKEN = \"<|name|>\"\n",
    "DEV_TOKEN = \"<|developer|>\"\n",
    "PUB_TOKEN = \"<|publisher|>\"\n",
    "DESC_TOKEN = \"<|description|>\"\n",
    "GENRES_TOKEN = \"<|genres|>\"\n",
    "GAME_TOKEN = \"<|game|>\"\n",
    "END_TOKEN = \"<|endoftext|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "little-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TOKENS = [NAME_TOKEN, DEV_TOKEN, PUB_TOKEN, DESC_TOKEN, GENRES_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "editorial-jordan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "increased-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/datasetv2.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hidden-burst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>name</th>\n",
       "      <th>developer</th>\n",
       "      <th>publisher</th>\n",
       "      <th>genres</th>\n",
       "      <th>description</th>\n",
       "      <th>header_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Action</td>\n",
       "      <td>Play the world's number 1 online action game. ...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/10/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Team Fortress Classic</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Action</td>\n",
       "      <td>One of the most popular online action games of...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/20/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Day of Defeat</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Action</td>\n",
       "      <td>Enlist in an intense brand of Axis vs. Allied ...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/30/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Deathmatch Classic</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Action</td>\n",
       "      <td>Enjoy fast-paced multiplayer gaming with Death...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/40/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Half-Life: Opposing Force</td>\n",
       "      <td>Gearbox Software</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Action</td>\n",
       "      <td>Return to the Black Mesa Research Facility as ...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/50/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid                       name         developer publisher  genres  \\\n",
       "0     10             Counter-Strike             Valve     Valve  Action   \n",
       "1     20      Team Fortress Classic             Valve     Valve  Action   \n",
       "2     30              Day of Defeat             Valve     Valve  Action   \n",
       "3     40         Deathmatch Classic             Valve     Valve  Action   \n",
       "4     50  Half-Life: Opposing Force  Gearbox Software     Valve  Action   \n",
       "\n",
       "                                         description  \\\n",
       "0  Play the world's number 1 online action game. ...   \n",
       "1  One of the most popular online action games of...   \n",
       "2  Enlist in an intense brand of Axis vs. Allied ...   \n",
       "3  Enjoy fast-paced multiplayer gaming with Death...   \n",
       "4  Return to the Black Mesa Research Facility as ...   \n",
       "\n",
       "                                        header_image  \n",
       "0  https://steamcdn-a.akamaihd.net/steam/apps/10/...  \n",
       "1  https://steamcdn-a.akamaihd.net/steam/apps/20/...  \n",
       "2  https://steamcdn-a.akamaihd.net/steam/apps/30/...  \n",
       "3  https://steamcdn-a.akamaihd.net/steam/apps/40/...  \n",
       "4  https://steamcdn-a.akamaihd.net/steam/apps/50/...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-camel",
   "metadata": {},
   "source": [
    "# Loading and Testing the Model\n",
    "\n",
    "Hugging Face Transformers makes it really easy to load pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = df.description.apply(lambda x: \" \".join(x.split()[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-overview",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = random.choice(prompts)\n",
    "prompt_encoded = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "output = model.generate(\n",
    "    prompt_encoded,\n",
    "    do_sample=True, \n",
    "    max_length=500, \n",
    "    top_k=50, \n",
    "    top_p=0.95,\n",
    "    no_repeat_ngram_size=5,\n",
    ")\n",
    "output_decoded = tokenizer.decode(output[0])\n",
    "\n",
    "\n",
    "print(prompt)\n",
    "print(output_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenizer\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-launch",
   "metadata": {},
   "source": [
    "# Fine-Tuning the Model to Generate Video Game Titles (Names)\n",
    "\n",
    "The output already looks fantastic, but let's fine-tune the model to get even better results.\n",
    "\n",
    "I'm going to work on the video game name generation first as a POC. We can use a special token, for example `<|name|>` as a prompt instead of needing words to prompt the title generation.\n",
    " \n",
    "See: https://towardsdatascience.com/natural-language-generation-part-2-gpt-2-and-huggingface-f3acb35bc86a\n",
    "\n",
    "So all we really need to do is format our data in with the prompt token (for this task, `<|name|>`) and the end of text token, which is built into the pretrained tokenizer: `<|endoftext|>` and fine-tune the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example formatted name\n",
    "name = df.name[0]\n",
    "formatted_name = f\"{NAME_TOKEN}{name}{END_TOKEN}\"\n",
    "print(formatted_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_formatted(file, list_of_texts, start_token, end_token):\n",
    "    for text in list_of_texts:\n",
    "        formatted_text = f\"{start_token}{text}{end_token}\"\n",
    "        file.write(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into train and validation\n",
    "train, validation = train_test_split(df.name, train_size=0.85, random_state=42)\n",
    "\n",
    "print(\"train count:\", train.count())\n",
    "print(\"validation count:\", validation.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/training/name_train.txt\", \"w\") as f:\n",
    "#     save_formatted(f, train, NAME_TOKEN, END_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/training/name_val.txt\", \"w\") as f:\n",
    "#     save_formatted(f, validation, NAME_TOKEN, END_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-lingerie",
   "metadata": {},
   "source": [
    "# Testing the Fine-tuned Name Model\n",
    "\n",
    "I used a GPU cloud provider to fine-tune the pretrained GPT2-medium model using the `scripts/train-name.sh` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"../data/models/gpt2-name\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"../data/models/gpt2-name\", pad_token_id=tokenizer.eos_token_id).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_encoded = tokenizer.encode(NAME_TOKEN, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "output = model.generate(\n",
    "    prompt_encoded,\n",
    "    do_sample=True, \n",
    "    max_length=500, \n",
    "    top_k=50, \n",
    "    top_p=0.95,\n",
    "    no_repeat_ngram_size=5,\n",
    ")\n",
    "output_decoded = tokenizer.decode(output[0])\n",
    "\n",
    "\n",
    "print(output_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-angle",
   "metadata": {},
   "source": [
    "This looks great, now I'll train a model that can generate each type of text we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenizer\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-uncle",
   "metadata": {},
   "source": [
    "# Compiling the Dataset for All Types of Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-score",
   "metadata": {},
   "source": [
    "We will have one unified dataset that has text that has the tokens: `<|name|>`, `<|developer|>`, `<|publisher|>`, `<|description|>`, `<|genres|>`, and of course `<|endoftext|>`.\n",
    "\n",
    "Each example will consist of one of the class tokens, then some text, and then the end token. It would be nice to be able to generate all the text for a game with a single `<|game|>` token, so I'll also test training a model to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    NAME_TOKEN: df.name,\n",
    "    DEV_TOKEN: df.developer,\n",
    "    PUB_TOKEN: df.publisher,\n",
    "    DESC_TOKEN: df.description,\n",
    "    GENRES_TOKEN: df.genres\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-swiss",
   "metadata": {},
   "source": [
    "## Separate Token Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-defeat",
   "metadata": {},
   "source": [
    "Here I am getting only the unique values because I don't need the outputs to be representative of the distribution dataset itself, but better representative of the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "labels = []\n",
    "\n",
    "for start_token, col in columns.items():\n",
    "    values = col.unique().tolist()\n",
    "    corpus.extend(\n",
    "        [f\"{start_token}{value}{END_TOKEN}\" for value in values]\n",
    "    )\n",
    "    labels.extend(\n",
    "        [start_token for _ in values]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-globe",
   "metadata": {},
   "source": [
    "We can validate the length of the corpus makes sense because we have ~27k examples, and 5 columns with many of the values in 3 of the columns being duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_length_corpus = 0\n",
    "for _, v in columns.items():\n",
    "    print(v.name, v.count(), len(v.unique()))\n",
    "    expected_length_corpus += len(v.unique())\n",
    "\n",
    "print(\"expected_length_corpus:\", expected_length_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-guidance",
   "metadata": {},
   "source": [
    "Here we split the corpus into the train and validation sets. Notice that we stratify using the labels to get a proportional number of each class in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(corpus, train_size=0.85, shuffle=True, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-malaysia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train), train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-silicon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(val), val[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-mechanics",
   "metadata": {},
   "source": [
    "Here is a horribly inefficient and hacky way of validating the stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(train).apply(lambda x: x.split(\"<|\")[1].split(\"|>\")[0]).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(val).apply(lambda x: x.split(\"<|\")[1].split(\"|>\")[0]).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-currency",
   "metadata": {},
   "source": [
    "Close enough :) Now we just save our train and val sets to two text files again and train a new model with this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/training/all_train.txt\", \"w\") as f:\n",
    "#     f.write(\"\".join(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/training/all_val.txt\", \"w\") as f:\n",
    "#     f.write(\"\".join(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-proposal",
   "metadata": {},
   "source": [
    "## Dataset for One-Shot Generation\n",
    "\n",
    "Now I'll create another corpus that wraps all of the fields and should allow us to generate games with more cohesive attributes. I also don't expect there to be too many duplicate games in the dataset so I haven't removed any for this dataset.\n",
    "\n",
    "I'm less optimistic about this approach, but we'll see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    game_text = (f\"{GAME_TOKEN}{NAME_TOKEN}{row['name']}{DEV_TOKEN}{row.developer}\"\n",
    "                 f\"{PUB_TOKEN}{row.publisher}{DESC_TOKEN}{row.description}{END_TOKEN}\")\n",
    "    \n",
    "    corpus.append(game_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-young",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(corpus, train_size=0.85, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/training/game_train.txt\", \"w\") as f:\n",
    "#     f.write(\"\".join(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/training/game_val.txt\", \"w\") as f:\n",
    "#     f.write(\"\".join(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-convenience",
   "metadata": {},
   "source": [
    "# Testing the Multi-Class Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "altered-trail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27048.000000\n",
       "mean       215.238317\n",
       "std        173.034320\n",
       "min          1.000000\n",
       "25%        114.000000\n",
       "50%        174.000000\n",
       "75%        266.000000\n",
       "max       8376.000000\n",
       "Name: description, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description.apply(lambda x: len(x.split())).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-morning",
   "metadata": {},
   "source": [
    "Implementing methods to make this easier going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "major-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer_and_model(model_path: str) -> Tuple[GPT2TokenizerFast, GPT2LMHeadModel]:\n",
    "    tokenizer = GPT2TokenizerFast.from_pretrained(\"../data/models/gpt2-all-15000/\")\n",
    "    model = GPT2LMHeadModel.from_pretrained(\"../data/models/gpt2-all-15000/\", pad_token_id=tokenizer.eos_token_id)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "printable-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_LENGTHS = {\n",
    "    NAME_TOKEN: (1, None),\n",
    "    DEV_TOKEN: (1, None),\n",
    "    PUB_TOKEN: (1, None),\n",
    "    DESC_TOKEN: (200, None),\n",
    "    GENRES_TOKEN: (1, None)\n",
    "}\n",
    "\n",
    "def generate_text(tokenizer: GPT2TokenizerFast, model: GPT2LMHeadModel, start_token: str, **gen_kwargs) -> str:\n",
    "    \"\"\"Generate a single output of text. A different function would be needed to batch generation.\"\"\"\n",
    "    \n",
    "    prompt_encoded = tokenizer.encode(start_token, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    default_length = DEFAULT_LENGTHS.get(start_token, None)\n",
    "    if default_length is not None:\n",
    "        gen_kwargs[\"min_length\"] = default_length[0] + len(prompt_encoded[0])\n",
    "        gen_kwargs[\"max_length\"] = default_length[1] + len(prompt_encoded[0])\n",
    "\n",
    "    output = model.generate(\n",
    "        prompt_encoded,\n",
    "        do_sample=True, \n",
    "        top_k=50, \n",
    "        top_p=0.95,\n",
    "        no_repeat_ngram_size=5,\n",
    "        **gen_kwargs\n",
    "    )\n",
    "    output_decoded = tokenizer.decode(output[0])\n",
    "\n",
    "\n",
    "    return output_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "promising-dating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1024)\n",
       "    (wpe): Embedding(1024, 1024)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer, model = load_tokenizer_and_model(\"../data/models/gpt2-all-15000/\")\n",
    "\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cooperative-first",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-60f813c93831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPROMPT_TOKENS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-ddaa1de8824c>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(tokenizer, model, start_token, **gen_kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdefault_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"min_length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     output = model.generate(\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "game = {}\n",
    "\n",
    "for token in PROMPT_TOKENS:\n",
    "    game[token] = generate_text(tokenizer, model, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "productive-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenizer\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-database",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
